{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee471945",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff1a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "from typing import TypedDict, List\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"Missing GROQ_API_KEY in .env\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb8439",
   "metadata": {},
   "source": [
    "## AI PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AI Prompt using LangChain PromptTemplate\n",
    "LLM_SYSTEM_PROMPT = \"\"\"\n",
    "Role Definition:\n",
    "You are a an expert Software QA Leader with 10 years experience in saas sase environments.\n",
    "\n",
    "QA Instructions:\n",
    "Ensure all field content is precise, actionable, and professional.\n",
    "Follow the schema exactly: test_case_id, test_title, description, preconditions, test_steps, test_data, expected_result, comments.\n",
    "Do not add extra fields or text outside the schema.\n",
    "\n",
    "Requirement Context:\n",
    "You will be provided with a user story that outlines specific software requirements.\n",
    "I want you to analyze the user story in depth and generate a comprehensive, professional set of test cases, including E2E functional steps, edge, and boundary cases, to ensure complete test coverage for the full requirements defined in the user story.\n",
    "generate set of test cases to cover all aspects of the user story, covering the following tests levels as much as you can:\n",
    "- Sanity test cases - cover acceptance tests\n",
    "- Functional test cases - cover main E2E functionality\n",
    "- Boundary test cases - cover edge limits\n",
    "- Negative test cases - cover invalid inputs and error handling\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a748bd",
   "metadata": {},
   "source": [
    "## Setup test case and test plan structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a41825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCase(BaseModel):\n",
    "    test_case_id: int = Field(..., description=\"Unique identifier for the test case.\")\n",
    "    test_title: str = Field(..., description=\"Title of the test case.\")\n",
    "    description: str = Field(..., description=\"Detailed description of what the test case covers.\")\n",
    "    preconditions: str = Field(..., description=\"Any setup required before execution.\")\n",
    "    test_steps: str = Field(..., description=\"Step-by-step execution guide.\")\n",
    "    test_data: str = Field(..., description=\"Input values required for the test.\")\n",
    "    expected_result: str = Field(..., description=\"The anticipated outcome.\")\n",
    "    comments: str = Field(..., description=\"Additional notes or observations.\")\n",
    "\n",
    "class TestPlan(BaseModel):\n",
    "    test_cases: List[TestCase]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd5e09",
   "metadata": {},
   "source": [
    "## Setup structured llm with Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f67cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap LLM with structured output\n",
    "structured_llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=GROQ_API_KEY\n",
    ")\n",
    "llm_with_structured_output = structured_llm.with_structured_output(TestPlan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55cad52",
   "metadata": {},
   "source": [
    "## Set graph state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGenState(TypedDict):\n",
    "    requirement: str\n",
    "    test_plan: List[dict]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6b1cbb",
   "metadata": {},
   "source": [
    "## Define the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dcfcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_requirement(state: TestGenState) -> TestGenState:\n",
    "    \"\"\"\n",
    "    Node: Parse Requirement\n",
    "    Purpose: Prepare the requirement text for the LLM.\n",
    "    Input: state['requirement'] (string)\n",
    "    Output: state['requirement'] (string)\n",
    "    \"\"\"\n",
    "    with open(\"..\\\\data\\\\requirements.txt\", \"r\") as f:\n",
    "        state[\"requirement\"] = f.read()\n",
    "    return state\n",
    "\n",
    "def generate_test_cases(state: TestGenState) -> TestGenState:\n",
    "    \"\"\"Generate structured test cases directly from requirement text.\"\"\"\n",
    "    messages = [\n",
    "    SystemMessage(content=LLM_SYSTEM_PROMPT),\n",
    "    HumanMessage(content=state[\"requirement\"])\n",
    "]\n",
    "    resp = llm_with_structured_output.invoke(messages) \n",
    "    print(resp)\n",
    "    # resp is already a TestPlan object\n",
    "    state[\"test_plan\"] = [tc.dict() for tc in resp.test_cases]\n",
    "    return state\n",
    "\n",
    "\n",
    "def export_tests(state: TestGenState, file_path=\"test_cases.csv\") -> TestGenState:\n",
    "    \"\"\"Node: Export all tests to CSV and display DataFrame.\"\"\"\n",
    "    df = pd.DataFrame(state.get(\"test_plan\", []))\n",
    "    df.to_csv(file_path, index=False)\n",
    "    display(df)\n",
    "    state[\"exported_file\"] = file_path\n",
    "    return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728940f",
   "metadata": {},
   "source": [
    "## setup the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(TestGenState)\n",
    "workflow.add_node(\"parse\", parse_requirement)\n",
    "workflow.add_node(\"generate_tests\", generate_test_cases)\n",
    "workflow.add_node(\"export\", export_tests)\n",
    "\n",
    "workflow.set_entry_point(\"parse\")\n",
    "\n",
    "# Normal flow\n",
    "workflow.add_edge(\"parse\", \"generate_tests\")\n",
    "workflow.add_edge(\"generate_tests\", \"export\")\n",
    "\n",
    "\n",
    "workflow.add_edge(\"export\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e85bb",
   "metadata": {},
   "source": [
    "## Invoke the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e054048",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
